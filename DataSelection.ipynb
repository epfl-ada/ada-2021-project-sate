{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5ea13c",
   "metadata": {},
   "source": [
    "# TO RUN : importS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e76d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "sns.set(font_scale = 1.3, rc = {'figure.figsize':(10,6)})\n",
    "sns.set_palette('colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991cb90e",
   "metadata": {},
   "source": [
    "# SELECT DATA OF INTEREST \n",
    "As the project focus on the debate on the right to bear arms in the USA, the first task consist on selecting the data related to this topic. To do so, we used a lexical field related to the topic, and select only the quotations that contain one or more words of this lexical field. <br> The lexical field determined is the set of the following words : 'gun','firearm','mass shooting','2nd Amendment','murder','homicide','gun shot','armed robbery','rifles','Second Amendment','Columbine', 'gun control'. <br> <br>\n",
    "The selected quotes are then stored in a new data file named `quotes-20__-extended.json.bz2` in form of a dataframe with some new columns. The columns added contain information about the speakers (gender, nationality, occupations, age (computed from the date of birth), ethnic group, party and religion). Such information are taken from the second dataset `speaker_attributes.parquet` itself built from wikidata information. Quotations that are not related to any seaker are not kept. <br> <br>\n",
    "As such selection of data requires a lot of time, we decided to only treat the quotations of 2017 for this part of the project. The corresponding file having a weight of 5 Go, it contains way enough quotation to perform first statistic tests and check if our project is feasible. <br>\n",
    "This is also why we decide to save the most information possible about the speaker. <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231e0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_field = ['gun','firearm','mass shooting','2nd Amendment','homicide','gun shot','armed robbery','rifles','Second Amendment','Columbine', 'gun control']\n",
    "\n",
    "speakers = pd.read_parquet(data_folder + 'speaker_attributes.parquet')\n",
    "label = pd.read_csv(data_folder + 'wikidata_labels_descriptions_quotebank.csv.bz2', compression='bz2', index_col='QID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = data_folder + 'quotes-2017.json.bz2' \n",
    "path_to_out = data_folder + 'quotes-2017-extended-new.json.bz2'\n",
    "\n",
    "iter = 0\n",
    "nb_occ = 0\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "\n",
    "            iter += 1\n",
    "            if instance['numOccurrences'] is not None:\n",
    "                nb_occ += instance['numOccurrences']\n",
    "\n",
    "            if (iter % 100000 == 0):\n",
    "                print('nombre de citations lus: {}'.format(iter))\n",
    "\n",
    "            if any(substring.lower() in instance['quotation'].lower() for substring in lexical_field) and instance['qids'] != []: #We keep only quotation containing words of the lexical field and where there is a speaker\n",
    "                speaker = speakers.loc[speakers['id'] == instance['qids'][0]].squeeze()\n",
    "\n",
    "                #We add nationality\n",
    "                if speaker.nationality is not None:\n",
    "                    instance['nationality'] = []\n",
    "                    for i in speaker['nationality']:\n",
    "                        nat = label.loc[i]['Label']\n",
    "                        instance['nationality'].append(nat)\n",
    "                else:\n",
    "                    instance['nationality'] = None\n",
    "                    \n",
    "                #We add the gender\n",
    "                if speaker.gender is not None:\n",
    "                    instance['gender'] = []\n",
    "                    for i in speaker['gender']:\n",
    "                        gend = label.loc[i]['Label']\n",
    "                        instance['gender'].append(gend)\n",
    "                else:\n",
    "                    instance['gender'] = None\n",
    "\n",
    "                #We add the occupations\n",
    "                if speaker.occupation is not None:\n",
    "                    instance['occupation'] = []\n",
    "                    for i in speaker['occupation']:\n",
    "                        occ = label.loc[i]['Label']\n",
    "                        instance['occupation'].append(occ)\n",
    "                else:\n",
    "                    instance['occupation'] = None\n",
    "\n",
    "                #We add the date of birth\n",
    "                try:\n",
    "                    born = datetime.strptime(speaker.date_of_birth[0][1:11], \"%Y-%m-%d\").date()\n",
    "                    today = date.today()\n",
    "                    age = today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "                except:\n",
    "                    age = None\n",
    "                instance['age'] = age\n",
    "\n",
    "                #We add the ethnic group\n",
    "                if speaker.ethnic_group is not None:\n",
    "                    instance['ethnic_group'] = []\n",
    "                    for i in speaker['ethnic_group']:\n",
    "                        ethnic = label.loc[i]['Label']\n",
    "                        instance['ethnic_group'].append(ethnic)\n",
    "                else:\n",
    "                    instance['ethnic_group'] = None\n",
    "\n",
    "                #We add the party\n",
    "                if speaker.party is not None:\n",
    "                    instance['party'] = []\n",
    "                    for i in speaker['party']:\n",
    "                        part = label.loc[i]['Label']\n",
    "                        instance['party'].append(part)\n",
    "                else:\n",
    "                    instance['party'] = None\n",
    "\n",
    "                #We add the religion\n",
    "                if speaker.religion is not None:\n",
    "                    instance['religion'] = []\n",
    "                    for i in speaker['religion']:\n",
    "                        relig = label.loc[i]['Label']\n",
    "                        instance['religion'].append(relig)\n",
    "                else:\n",
    "                    instance['religion'] = None\n",
    "\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file\n",
    "\n",
    "                # to test\n",
    "                # if iter > 10000:\n",
    "                #     break\n",
    "\n",
    "print('iter = {i}'.format(i = iter))\n",
    "print('nb_occ = {n}'.format(n = nb_occ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6848c3f1",
   "metadata": {},
   "source": [
    "**Useful statistics :**   \n",
    "26 611 588 \"different\" quotes were extracted from 2017 newpapers.  \n",
    "Some of these quotes being mentionned in several articles, the total number of quotes found in the newspapers is 136 326 717."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
