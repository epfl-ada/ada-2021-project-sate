{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5ea13c",
   "metadata": {},
   "source": [
    "# TO RUN : imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e76d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import bz2\n",
    "import urllib\n",
    "from datetime import datetime, date\n",
    "\n",
    "data_folder = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991cb90e",
   "metadata": {},
   "source": [
    "# SELECT DATA OF INTEREST \n",
    "The project focusing on the debate of the right to bear arms in the USA, the first task consists in selecting the data related to this topic. To do so, we use a lexical field (named ***lexical_field*** in the code)  related to the topic, and select only the quotations, which contain one or more words of this lexical field. <br> The determined word bank is the set of the following words: 'gun', 'firearm', 'mass shooting', '2nd Amendment', 'homicide', 'gun shot', 'armed robbery', 'rifles', 'Second Amendment', 'Columbine', 'gun control'. The way the words have been chosen is explained in the `read.me`.  <br> <br> \n",
    "The selected quotes are then stored in a new data file named `quotes-20__-extended.json.bz2` in form of a dataframe with new columns. The added columns contain information about the speakers (gender, nationality, occupations, age (computed from the date of birth), ethnic group, political party and religion). Such information are taken from the second dataset `speaker_attributes.parquet`, built from wikidata information. Quotations that are not related to any seaker are not kept. <br> <br>\n",
    "This data preprocessing being long, we decide to only treat the quotations of 2017 for Milestone 2. The corresponding file have a total of more than 26 millions quotes, it contains way enough infomation to compute the first statistics and check if our project is feasible. <br>\n",
    "This is also why we decide to save the most information possible about the speaker. The quotations from the other years will be studied in Milestone 3.  <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231e0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_field = ['gun','firearm','mass shooting','2nd Amendment','homicide','gun shot','armed robbery','rifles','Second Amendment','Columbine', 'gun control']\n",
    "\n",
    "speakers = pd.read_parquet(data_folder + 'speaker_attributes.parquet')\n",
    "label = pd.read_csv(data_folder + 'wikidata_labels_descriptions_quotebank.csv.bz2', compression='bz2', index_col='QID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d38ff6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de citations lus: 100000\n",
      "nombre de citations lus: 200000\n",
      "nombre de citations lus: 300000\n",
      "nombre de citations lus: 400000\n",
      "nombre de citations lus: 500000\n",
      "nombre de citations lus: 600000\n",
      "nombre de citations lus: 700000\n",
      "nombre de citations lus: 800000\n",
      "nombre de citations lus: 900000\n",
      "nombre de citations lus: 1000000\n",
      "nombre de citations lus: 1100000\n",
      "nombre de citations lus: 1200000\n",
      "nombre de citations lus: 1300000\n",
      "nombre de citations lus: 1400000\n",
      "nombre de citations lus: 1500000\n",
      "nombre de citations lus: 1600000\n",
      "nombre de citations lus: 1700000\n",
      "nombre de citations lus: 1800000\n",
      "nombre de citations lus: 1900000\n",
      "nombre de citations lus: 2000000\n",
      "nombre de citations lus: 2100000\n",
      "nombre de citations lus: 2200000\n",
      "nombre de citations lus: 2300000\n",
      "nombre de citations lus: 2400000\n",
      "nombre de citations lus: 2500000\n",
      "nombre de citations lus: 2600000\n",
      "nombre de citations lus: 2700000\n",
      "nombre de citations lus: 2800000\n",
      "nombre de citations lus: 2900000\n",
      "nombre de citations lus: 3000000\n",
      "nombre de citations lus: 3100000\n",
      "nombre de citations lus: 3200000\n",
      "nombre de citations lus: 3300000\n",
      "nombre de citations lus: 3400000\n",
      "nombre de citations lus: 3500000\n",
      "nombre de citations lus: 3600000\n",
      "nombre de citations lus: 3700000\n",
      "nombre de citations lus: 3800000\n",
      "nombre de citations lus: 3900000\n",
      "nombre de citations lus: 4000000\n",
      "nombre de citations lus: 4100000\n",
      "nombre de citations lus: 4200000\n",
      "nombre de citations lus: 4300000\n",
      "nombre de citations lus: 4400000\n",
      "nombre de citations lus: 4500000\n",
      "nombre de citations lus: 4600000\n",
      "nombre de citations lus: 4700000\n",
      "nombre de citations lus: 4800000\n",
      "nombre de citations lus: 4900000\n",
      "nombre de citations lus: 5000000\n",
      "nombre de citations lus: 5100000\n",
      "nombre de citations lus: 5200000\n",
      "nombre de citations lus: 5300000\n",
      "nombre de citations lus: 5400000\n",
      "nombre de citations lus: 5500000\n",
      "nombre de citations lus: 5600000\n",
      "nombre de citations lus: 5700000\n",
      "nombre de citations lus: 5800000\n",
      "nombre de citations lus: 5900000\n",
      "nombre de citations lus: 6000000\n",
      "nombre de citations lus: 6100000\n",
      "nombre de citations lus: 6200000\n",
      "nombre de citations lus: 6300000\n",
      "nombre de citations lus: 6400000\n",
      "nombre de citations lus: 6500000\n",
      "nombre de citations lus: 6600000\n",
      "nombre de citations lus: 6700000\n",
      "nombre de citations lus: 6800000\n",
      "nombre de citations lus: 6900000\n",
      "nombre de citations lus: 7000000\n",
      "nombre de citations lus: 7100000\n",
      "nombre de citations lus: 7200000\n",
      "nombre de citations lus: 7300000\n",
      "nombre de citations lus: 7400000\n",
      "nombre de citations lus: 7500000\n",
      "nombre de citations lus: 7600000\n",
      "nombre de citations lus: 7700000\n",
      "nombre de citations lus: 7800000\n",
      "nombre de citations lus: 7900000\n",
      "nombre de citations lus: 8000000\n",
      "nombre de citations lus: 8100000\n",
      "nombre de citations lus: 8200000\n",
      "nombre de citations lus: 8300000\n",
      "nombre de citations lus: 8400000\n",
      "nombre de citations lus: 8500000\n",
      "nombre de citations lus: 8600000\n",
      "nombre de citations lus: 8700000\n",
      "nombre de citations lus: 8800000\n",
      "nombre de citations lus: 8900000\n",
      "nombre de citations lus: 9000000\n",
      "nombre de citations lus: 9100000\n",
      "nombre de citations lus: 9200000\n",
      "nombre de citations lus: 9300000\n",
      "nombre de citations lus: 9400000\n",
      "nombre de citations lus: 9500000\n",
      "nombre de citations lus: 9600000\n",
      "nombre de citations lus: 9700000\n",
      "nombre de citations lus: 9800000\n",
      "nombre de citations lus: 9900000\n",
      "nombre de citations lus: 10000000\n",
      "nombre de citations lus: 10100000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Q6363085'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Q6363085'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ny/b3wvz99s2fn97pvfq2g997800000gn/T/ipykernel_36200/1331806470.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspeaker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'occupation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Q99753484'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                             \u001b[0mocc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                             \u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'occupation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mocc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3737\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3739\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3741\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Q6363085'"
     ]
    }
   ],
   "source": [
    "path_to_file = data_folder + 'quotes-2019.json.bz2' \n",
    "path_to_out = data_folder + 'quotes-2019-extended.json.bz2'\n",
    "\n",
    "iter = 0\n",
    "nb_occ = 0\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            \n",
    "            #To count the number of citations\n",
    "            iter += 1\n",
    "            \n",
    "            #To count the total number of occurences\n",
    "            if instance['numOccurrences'] is not None:\n",
    "                nb_occ += instance['numOccurrences']\n",
    "\n",
    "            #To check the progress of the algorithm, because it takes multiple hours to run\n",
    "            if (iter % 100000 == 0):\n",
    "                print('nombre de citations lus: {}'.format(iter))\n",
    "\n",
    "            #We check if the quotation contains words from the lexical field\n",
    "            if any(substring.lower() in instance['quotation'].lower() for substring in lexical_field) and instance['qids'] != []: #We keep only quotation containing words of the lexical field and where there is a speaker\n",
    "                \n",
    "                #We load additional information about the speaker\n",
    "                speaker = speakers.loc[speakers['id'] == instance['qids'][0]].squeeze()\n",
    "\n",
    "                #We add nationality\n",
    "                if speaker.nationality is not None:\n",
    "                    instance['nationality'] = []\n",
    "                    for i in speaker['nationality']:\n",
    "                        nat = label.loc[i]['Label']\n",
    "                        instance['nationality'].append(nat)\n",
    "                else:\n",
    "                    instance['nationality'] = None\n",
    "                    \n",
    "                #We add the gender\n",
    "                if speaker.gender is not None:\n",
    "                    instance['gender'] = []\n",
    "                    for i in speaker['gender']:\n",
    "                        gend = label.loc[i]['Label']\n",
    "                        instance['gender'].append(gend)\n",
    "                else:\n",
    "                    instance['gender'] = None\n",
    "\n",
    "                #We add the occupations\n",
    "                \n",
    "               \n",
    "                    \n",
    "                \n",
    "                \n",
    "                if speaker.occupation is not None:\n",
    "                    instance['occupation'] = []\n",
    "                    for i in speaker['occupation']:\n",
    "                        if i != 'Q99753484':\n",
    "                            occ = label.loc[i]['Label']\n",
    "                            instance['occupation'].append(occ)\n",
    "                else:\n",
    "                    instance['occupation'] = None\n",
    "\n",
    "                #We add the age (computed from the date of birth)\n",
    "                #We use a try since the date is wrong (e.g. month = 0) at some places\n",
    "                try:\n",
    "                    born = datetime.strptime(speaker.date_of_birth[0][1:11], \"%Y-%m-%d\").date()\n",
    "                    today = date.today()\n",
    "                    age = today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "                except:\n",
    "                    age = None\n",
    "                instance['age'] = age\n",
    "\n",
    "                #We add the ethnic group\n",
    "                if speaker.ethnic_group is not None:\n",
    "                    instance['ethnic_group'] = []\n",
    "                    for i in speaker['ethnic_group']:\n",
    "                        ethnic = label.loc[i]['Label']\n",
    "                        instance['ethnic_group'].append(ethnic)\n",
    "                else:\n",
    "                    instance['ethnic_group'] = None\n",
    "\n",
    "                #We add the party\n",
    "                if speaker.party is not None:\n",
    "                    instance['party'] = []\n",
    "                    for i in speaker['party']:\n",
    "                        part = label.loc[i]['Label']\n",
    "                        instance['party'].append(part)\n",
    "                else:\n",
    "                    instance['party'] = None\n",
    "\n",
    "                #We add the religion\n",
    "                if speaker.religion is not None:\n",
    "                    instance['religion'] = []\n",
    "                    for i in speaker['religion']:\n",
    "                        relig = label.loc[i]['Label']\n",
    "                        instance['religion'].append(relig)\n",
    "                else:\n",
    "                    instance['religion'] = None\n",
    "\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file\n",
    "\n",
    "\n",
    "print('iter = {i}'.format(i = iter))\n",
    "print('nb_occ = {n}'.format(n = nb_occ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6848c3f1",
   "metadata": {},
   "source": [
    "**Useful statistics :**   \n",
    "Number of \"different\" quotes in the 2017 newpapers:  26 611 588.\n",
    "Some of these quotes being mentionned in several articles (number of occurence >1), the total number of quotes in 2017 is: 136 326 717."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
