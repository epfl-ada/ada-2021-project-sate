{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import bz2\n",
    "import urllib\n",
    "from datetime import datetime, date\n",
    "\n",
    "data_folder = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/theopatron/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.477, 'pos': 0.523, 'compound': 0.6588}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "sid.polarity_scores('test: The food was great!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of extended files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOR THE TIMELINE\n",
    "keep quotation mentionning guns \n",
    "\n",
    "### FOR THE ANALYSIS\n",
    "keep quotation mentionning guns <br/>\n",
    "keep only those that have a speaker <br/>\n",
    "keep american speakers <br/>\n",
    "add colums corresponding to characteristics of speaker <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_field = ['gun','firearm','mass shooting','2nd Amendment','homicide','gun shot','armed robbery','rifles','Second Amendment','Columbine', 'gun control']\n",
    "\n",
    "speakers = pd.read_parquet(data_folder + 'speaker_attributes.parquet')\n",
    "label = pd.read_csv(data_folder + 'wikidata_labels_descriptions_quotebank.csv.bz2', compression='bz2', index_col='QID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de citations lus: 1000\n",
      "nombre de citations lus: 2000\n",
      "nombre de citations lus: 3000\n",
      "nombre de citations lus: 4000\n",
      "nombre de citations lus: 5000\n",
      "nombre de citations lus: 6000\n",
      "nombre de citations lus: 7000\n",
      "nombre de citations lus: 8000\n",
      "nombre de citations lus: 9000\n",
      "nombre de citations lus: 10000\n",
      "iter = 10172\n",
      "nb_occ = 45227\n"
     ]
    }
   ],
   "source": [
    "path_to_file = data_folder + 'quotes-2017.json.bz2' \n",
    "path_to_out = data_folder + 'quotes-2017-extended-new.json.bz2'\n",
    "\n",
    "iter = 0\n",
    "nb_occ = 0\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "\n",
    "            iter += 1\n",
    "            if instance['numOccurrences'] is not None:\n",
    "                nb_occ += instance['numOccurrences']\n",
    "\n",
    "            if (iter % 100000 == 0):\n",
    "                print('nombre de citations lus: {}'.format(iter))\n",
    "\n",
    "            if any(substring.lower() in instance['quotation'].lower() for substring in lexical_field) and instance['qids'] != []: #We keep only quotation containing words of the lexical field and where there is a speaker\n",
    "                speaker = speakers.loc[speakers['id'] == instance['qids'][0]].squeeze()\n",
    "\n",
    "                #We add nationality\n",
    "                if speaker.nationality is not None:\n",
    "                    instance['nationality'] = []\n",
    "                    for i in speaker['nationality']:\n",
    "                        nat = label.loc[i]['Label']\n",
    "                        instance['nationality'].append(nat)\n",
    "                else:\n",
    "                    instance['nationality'] = None\n",
    "                    \n",
    "                #We add the gender\n",
    "                if speaker.gender is not None:\n",
    "                    instance['gender'] = []\n",
    "                    for i in speaker['gender']:\n",
    "                        gend = label.loc[i]['Label']\n",
    "                        instance['gender'].append(gend)\n",
    "                else:\n",
    "                    instance['gender'] = None\n",
    "\n",
    "                #We add the occupations\n",
    "                if speaker.occupation is not None:\n",
    "                    instance['occupation'] = []\n",
    "                    for i in speaker['occupation']:\n",
    "                        occ = label.loc[i]['Label']\n",
    "                        instance['occupation'].append(occ)\n",
    "                else:\n",
    "                    instance['occupation'] = None\n",
    "\n",
    "                #We add the date of birth\n",
    "                try:\n",
    "                    born = datetime.strptime(speaker.date_of_birth[0][1:11], \"%Y-%m-%d\").date()\n",
    "                    today = date.today()\n",
    "                    age = today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "                except:\n",
    "                    age = None\n",
    "                instance['age'] = age\n",
    "\n",
    "                #We add the ethnic group\n",
    "                if speaker.ethnic_group is not None:\n",
    "                    instance['ethnic_group'] = []\n",
    "                    for i in speaker['ethnic_group']:\n",
    "                        ethnic = label.loc[i]['Label']\n",
    "                        instance['ethnic_group'].append(ethnic)\n",
    "                else:\n",
    "                    instance['ethnic_group'] = None\n",
    "\n",
    "                #We add the party\n",
    "                if speaker.party is not None:\n",
    "                    instance['party'] = []\n",
    "                    for i in speaker['party']:\n",
    "                        part = label.loc[i]['Label']\n",
    "                        instance['party'].append(part)\n",
    "                else:\n",
    "                    instance['party'] = None\n",
    "\n",
    "                #We add the religion\n",
    "                if speaker.religion is not None:\n",
    "                    instance['religion'] = []\n",
    "                    for i in speaker['religion']:\n",
    "                        relig = label.loc[i]['Label']\n",
    "                        instance['religion'].append(relig)\n",
    "                else:\n",
    "                    instance['religion'] = None\n",
    "\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file\n",
    "\n",
    "                # to test\n",
    "                # if iter > 10000:\n",
    "                #     break\n",
    "\n",
    "print('iter = {i}'.format(i = iter))\n",
    "print('nb_occ = {n}'.format(n = nb_occ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 36462 rows\n"
     ]
    }
   ],
   "source": [
    "def process_chunk(chunk):\n",
    "    print(f'Processing chunk with {len(chunk)} rows')\n",
    "\n",
    "with pd.read_json(data_folder + 'quotes-2017-extended.json.bz2', lines=True, compression='bz2', chunksize=100000) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        process_chunk(chunk)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
