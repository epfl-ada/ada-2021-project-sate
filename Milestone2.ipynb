{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727de0ea",
   "metadata": {},
   "source": [
    "# TO RUN : importS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "sns.set(font_scale = 1.3, rc = {'figure.figsize':(10,6)})\n",
    "sns.set_palette('colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda5645",
   "metadata": {},
   "source": [
    "# 1- SELECT DATA OF INTEREST \n",
    "As the project focus on the debate on the right to bear arms in the USA, the first task consist on selecting the data related to this topic. To do so, we used a lexical field related to the topic, and select only the quotations that contain one or more words of this lexical field. <br> The lexical field determined is the set of the following words : 'gun','firearm','mass shooting','2nd Amendment','murder','homicide','gun shot','armed robbery','rifles','Second Amendment','Columbine', 'gun control'. <br> <br>\n",
    "The selected quotes are then stored in a new data file named `quotes-20__-extended.json.bz2` in form of a dataframe with some new columns. The columns added contain information about the speakers (gender, nationality, occupations, age (computed from the date of birth), ethnic group, party and religion). Such information are taken from the second dataset `speaker_attributes.parquet` itself built from wikidata information. Quotations that are not related to any seaker are not kept. <br> <br>\n",
    "As such selection of data requires a lot of time, we decided to only treat the quotations of 2017 for this part of the project. The corresponding file having a weight of 5 Go, it contains way enough quotation to perform first statistic tests and check if our project is feasible. <br>\n",
    "This is also why we decide to save the most information possible about the speaker. <br> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358232ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_field = ['gun','firearm','mass shooting','2nd Amendment','homicide','gun shot','armed robbery','rifles','Second Amendment','Columbine', 'gun control']\n",
    "\n",
    "speakers = pd.read_parquet(data_folder + 'speaker_attributes.parquet')\n",
    "label = pd.read_csv(data_folder + 'wikidata_labels_descriptions_quotebank.csv.bz2', compression='bz2', index_col='QID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeadda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = data_folder + 'quotes-2017.json.bz2' \n",
    "path_to_out = data_folder + 'quotes-2017-extended-new.json.bz2'\n",
    "\n",
    "iter = 0\n",
    "nb_occ = 0\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "\n",
    "            iter += 1\n",
    "            if instance['numOccurrences'] is not None:\n",
    "                nb_occ += instance['numOccurrences']\n",
    "\n",
    "            if (iter % 100000 == 0):\n",
    "                print('nombre de citations lus: {}'.format(iter))\n",
    "\n",
    "            if any(substring.lower() in instance['quotation'].lower() for substring in lexical_field) and instance['qids'] != []: #We keep only quotation containing words of the lexical field and where there is a speaker\n",
    "                speaker = speakers.loc[speakers['id'] == instance['qids'][0]].squeeze()\n",
    "\n",
    "                #We add nationality\n",
    "                if speaker.nationality is not None:\n",
    "                    instance['nationality'] = []\n",
    "                    for i in speaker['nationality']:\n",
    "                        nat = label.loc[i]['Label']\n",
    "                        instance['nationality'].append(nat)\n",
    "                else:\n",
    "                    instance['nationality'] = None\n",
    "                    \n",
    "                #We add the gender\n",
    "                if speaker.gender is not None:\n",
    "                    instance['gender'] = []\n",
    "                    for i in speaker['gender']:\n",
    "                        gend = label.loc[i]['Label']\n",
    "                        instance['gender'].append(gend)\n",
    "                else:\n",
    "                    instance['gender'] = None\n",
    "\n",
    "                #We add the occupations\n",
    "                if speaker.occupation is not None:\n",
    "                    instance['occupation'] = []\n",
    "                    for i in speaker['occupation']:\n",
    "                        occ = label.loc[i]['Label']\n",
    "                        instance['occupation'].append(occ)\n",
    "                else:\n",
    "                    instance['occupation'] = None\n",
    "\n",
    "                #We add the date of birth\n",
    "                try:\n",
    "                    born = datetime.strptime(speaker.date_of_birth[0][1:11], \"%Y-%m-%d\").date()\n",
    "                    today = date.today()\n",
    "                    age = today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "                except:\n",
    "                    age = None\n",
    "                instance['age'] = age\n",
    "\n",
    "                #We add the ethnic group\n",
    "                if speaker.ethnic_group is not None:\n",
    "                    instance['ethnic_group'] = []\n",
    "                    for i in speaker['ethnic_group']:\n",
    "                        ethnic = label.loc[i]['Label']\n",
    "                        instance['ethnic_group'].append(ethnic)\n",
    "                else:\n",
    "                    instance['ethnic_group'] = None\n",
    "\n",
    "                #We add the party\n",
    "                if speaker.party is not None:\n",
    "                    instance['party'] = []\n",
    "                    for i in speaker['party']:\n",
    "                        part = label.loc[i]['Label']\n",
    "                        instance['party'].append(part)\n",
    "                else:\n",
    "                    instance['party'] = None\n",
    "\n",
    "                #We add the religion\n",
    "                if speaker.religion is not None:\n",
    "                    instance['religion'] = []\n",
    "                    for i in speaker['religion']:\n",
    "                        relig = label.loc[i]['Label']\n",
    "                        instance['religion'].append(relig)\n",
    "                else:\n",
    "                    instance['religion'] = None\n",
    "\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file\n",
    "\n",
    "                # to test\n",
    "                # if iter > 10000:\n",
    "                #     break\n",
    "\n",
    "print('iter = {i}'.format(i = iter))\n",
    "print('nb_occ = {n}'.format(n = nb_occ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf888d8",
   "metadata": {},
   "source": [
    "# 2- FIRST STATISTICS\n",
    "Here, we try to extract a few basic statistics to make sure we have the necessary data to perform the project. Indeed, after selecting the quotations of interests (the ones related to arms in the USA), we want to make sure these datas are sufficiently numerous to perform an actual study on the right to bear arms in the USA. We also want to check if our research questions are reasonnnable and can be solved from our data. <br>\n",
    "<br>\n",
    "First, we get a sense of the quantity of actual quotations speaking about arms, and we compute its share in the total quotes dataset of 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5adf17d",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "The new dataset `quotes-2017-extended.json` can be loaded from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add8f248",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12728/4245980217.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgunquotes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/quotes-2017-extended.json.bz2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bz2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgunquotes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "gunquotes = pd.read_json('data/quotes-2017-extended.json.bz2', lines=True, compression='bz2')\n",
    "gunquotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14856b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nblines_gunquotes = gunquotes.shape[0]\n",
    "nbtot_gunquotes = gunquotes['numOccurrences'].sum()\n",
    "print(nblines_gunquotes)\n",
    "print(nbtot_gunquotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7cb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "share_gunquotes = 100 * nblines_gunquotes / nblines_totquotes\n",
    "sharetot_gunquotes = 100 * nbtot_gunquotes / nbtot_totquotes\n",
    "print(share_gunquotes)\n",
    "print(sharetot_gunquotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227d108",
   "metadata": {},
   "source": [
    "**Analysis :** <br>\n",
    "The new dataset (with only selected quotes) contain 36462 different quotes, some of which are quoted in several articles. Thus, there is a total number of 212199 quotes found in the 2017 newspapers that are related to our topic. <br>\n",
    "This represent a share of     % of the total quotations of 2017. Even if this share is very small, the size of the original 2017 dataset being very huge, it is not surprising and 36462 different quotations is already quite a lot of data for 1 year for our project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28587b04",
   "metadata": {},
   "source": [
    "### A first timeline for 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c3a3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions for the following plots\n",
    "\n",
    "def show_values(axs, orient=\"v\", space=.01):\n",
    "    def _single(ax):\n",
    "        if orient == \"v\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() / 2\n",
    "                _y = p.get_y() + p.get_height() + (p.get_height()*0.01)\n",
    "                value = '{:.0f}'.format(p.get_height())\n",
    "                ax.text(_x, _y, value, ha=\"center\") \n",
    "        elif orient == \"h\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() + float(space)\n",
    "                _y = p.get_y() + p.get_height() - (p.get_height()*0.5)\n",
    "                value = '{:.0f}'.format(p.get_width())\n",
    "                ax.text(_x, _y, value, ha=\"left\")\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _single(ax)\n",
    "    else:\n",
    "        _single(axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca9e73",
   "metadata": {},
   "source": [
    "#### 'Gun quotes' timeline per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de03efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot of the nb of quotes related to guns in function of the month\n",
    "\n",
    "gunquotes['dateWithoutTime'] = gunquotes['date'].dt.normalize()\n",
    "\n",
    "quotes_perMonth = gunquotes.groupby(gunquotes['dateWithoutTime'].dt.month).numOccurrences.sum()\n",
    "print(quotes_perMonth)\n",
    "print(quotes_perMonth.sum())\n",
    "# ax = sns.barplot(x=gunquotes.groupby(gunquotes[\"dateWithoutTime\"].dt.month), y=gunquotes.groupby(gunquotes['dateWithoutTime'].dt.month).numOccurrences.sum())#, data=gunquotes)\n",
    "ax = sns.barplot(x=np.linspace(1,12,12), y=gunquotes.groupby(gunquotes['dateWithoutTime'].dt.month).numOccurrences.sum())#, data=gunquotes)\n",
    "# ax = sns.barplot(x=quotes_perMonth.index, y=quotes_perMonth)\n",
    "sns.set_color_codes(\"colorblind\")\n",
    "ax.set_xlabel('Months')\n",
    "ax.set_ylabel('Number of quotes')\n",
    "ax.set_title('Timeline of the gun-related quotations during the year 2017')\n",
    "ax.set_xticklabels(labels=['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'])\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()\n",
    "show_values(ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03065c82",
   "metadata": {},
   "source": [
    "**Analysis :** <br>\n",
    "The barplot reveals an unexpected big amount of quotations speaking about guns in the months of June and October. One can guess that this is due to an event that occured in this month. Indeed, for example the amounts of quotes in October can be explianed by the Las Vegas shooting of the 1st of October. To verfiy this guess we will look further at the distribution of the quotes in thess 2 months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe3874a",
   "metadata": {},
   "source": [
    "#### Zoom on the month of June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot of the nb of quotes related to guns in function of the date : zoom on JUNE\n",
    "\n",
    "june = gunquotes[(gunquotes['date'].dt.month == 6)]\n",
    "\n",
    "ax = sns.barplot(x=np.linspace(1,30,30, dtype='int'), y=june.groupby(june['dateWithoutTime']).numOccurrences.sum())#, data=gunquotes)\n",
    "sns.color_palette(\"tab10\")\n",
    "ax.set_xlabel('Days')\n",
    "ax.set_ylabel('Number of quotes')\n",
    "ax.set_title('Timeline of the gun-related quotations during the year 2017')\n",
    "#ax.set_xticklabels(labels=labs)\n",
    "plt.xticks(rotation=60)\n",
    "show_values(ax)\n",
    "plt.show()\n",
    "\n",
    "## Explanation :\n",
    "## https://www.nytimes.com/2017/06/26/us/politics/supreme-court-guns-public-california.html\n",
    "## https://www.pewresearch.org/social-trends/2017/06/22/americas-complex-relationship-with-guns/\n",
    "## Fusillade de l'entrainement républicain du match de baseball du Congrès le 14 juin 2017 : https://fr.wikipedia.org/wiki/Fusillade_de_l%27entrainement_r%C3%A9publicain_du_match_de_baseball_du_Congr%C3%A8s\n",
    "## Pizzagate shooters sentenced to 4 years of prison on the 22th of June 2017 : https://edition.cnn.com/2017/06/22/politics/pizzagate-sentencing/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1b1fb",
   "metadata": {},
   "source": [
    "**Analysis :**  \n",
    "TO COMPLETE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbeab84",
   "metadata": {},
   "source": [
    "#### Zoom on the month of October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa46dcd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gunquotes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12728/4067201151.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Plot of the nb of quotes related to guns in function of the date : zoom on OCTOBER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moctober\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgunquotes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgunquotes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# nb = october.groupby(october['dateWithoutTime']).numOccurrences.sum()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(nb.sum())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gunquotes' is not defined"
     ]
    }
   ],
   "source": [
    "## Plot of the nb of quotes related to guns in function of the date : zoom on OCTOBER\n",
    "\n",
    "october = gunquotes[(gunquotes['date'].dt.month == 10)]\n",
    "# nb = october.groupby(october['dateWithoutTime']).numOccurrences.sum()\n",
    "# print(nb.sum())\n",
    "\n",
    "ax = sns.barplot(x=np.linspace(1,31,31, dtype='int'), y=october.groupby(october['dateWithoutTime']).numOccurrences.sum())#, data=gunquotes)\n",
    "sns.color_palette(\"tab10\")\n",
    "ax.set_xlabel('Days')\n",
    "ax.set_ylabel('Number of quotes')\n",
    "ax.set_title('Timeline of the gun-related quotations during the year 2017')\n",
    "#ax.set_xticklabels(labels=labs)\n",
    "plt.xticks(rotation=60)\n",
    "show_values(ax)\n",
    "plt.show()\n",
    "\n",
    "## Explanation : Las Vegas shooting on the 1st of October 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0f081",
   "metadata": {},
   "source": [
    "**Analysis :**  \n",
    "Most of the quotations of the mmonth of October were found in articles of the 2nd of October, the day after the mass shooting of Las Vegas. This thus confirms our guess that these articles spoke about this event. The following days, also show a higher amount of quotations, revealing that the medias continued to talk about the tragedy in the following days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad67b7b",
   "metadata": {},
   "source": [
    "# 3- MATCHING OF THE DATASET FOR SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ddebf5",
   "metadata": {},
   "source": [
    "### Matching of the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b3975a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f8f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e4f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f393841",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555eda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5037a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f7f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f5c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6b7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7099cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2eab8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d70643ce",
   "metadata": {},
   "source": [
    "# Conclusions on the following of the project  \n",
    "TO COMPLETE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
